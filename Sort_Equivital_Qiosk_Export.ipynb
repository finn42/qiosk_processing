{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check on the files exported by Equivital Qiosk\n",
    "for RITMO\n",
    "\n",
    "TODO\n",
    "\n",
    "Plot and review measurements from equivital sensors as output by the Equivital Manager app.\n",
    "(Every program produces different formated files and it's a pain.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import datetime as dt\n",
    "import math\n",
    "import numpy as np \n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# import heartpy as hp\n",
    "\n",
    "from scipy.signal import butter,filtfilt\n",
    "from scipy import interpolate\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions for data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_dets(eq_file_loc): # for csv files output by the qiosk app\n",
    "    filings = eq_file_loc.split('\\\\')\n",
    "    file_name = filings[-1]\n",
    "    f = file_name.split('-')\n",
    "    Signal = f[0]\n",
    "    DevName = f[1]#filings[-2]\n",
    "    DevID = int(f[2])\n",
    "    fileDate = int(f[3][:6]) # interpret as datetime datatype?\n",
    "    # sometimes the session numbering fails and we get files with the same session number but an additiona _0 or _1\n",
    "    # how to number this? What errors are producing these session numbers?\n",
    "    if len(f[3].split('_'))==2: # we have an additional numbering to work into the sessions. :[\n",
    "        Sessn1 = int(f[3].split('_')[0][6:8])\n",
    "        Sessn2 = int(f[3].split('_')[1].split('.')[0])\n",
    "        Session = (Sessn1+1)*100 + Sessn2+1 # yes this makes the session numbers huge out of nowhere, but it won't overlap with QIOSKs proper numbering that goes up to 99\n",
    "    else:\n",
    "        Session = int(f[3][6:8])\n",
    "    fileSize = os.path.getsize(eq_file_loc)\n",
    "\n",
    "    File_dets={'Signal':Signal, #f[-2].split('_')[-1],\n",
    "       'DevName':DevName,\n",
    "       'ID':DevID, \n",
    "       'Date':fileDate,\n",
    "       'Session':Session,\n",
    "       'FileName':file_name,\n",
    "       'FileType':'csv',\n",
    "       'FileSize': fileSize,\n",
    "       'FullLoc':eq_file_loc}\n",
    "    return File_dets\n",
    "\n",
    "def data_dets(eq_file_loc): #rec_start = V['DateTime'].iloc[0]\n",
    "    # this file pulls recording details from the file name and from inside file to aggregate all metadata\n",
    "    filings = eq_file_loc.split('\\\\')\n",
    "    file_name = filings[-1]\n",
    "    f = file_name.split('-')\n",
    "    Signal = f[0]\n",
    "    DevName = f[1]#filings[-2]\n",
    "    DevID = int(f[2])\n",
    "    fileDate = int(f[3][:6]) # interpret as datetime datatype?\n",
    "    # sometimes the session numbering fails and we get files with the same session number but an additiona _0 or _1\n",
    "    # how to number this? What errors are producing these session numbers?\n",
    "    if len(f[3].split('_'))==2: # we have an additional numbering to work into the sessions. :[\n",
    "        Sessn1 = int(f[3].split('_')[0][6:8])\n",
    "        Sessn2 = int(f[3].split('_')[1].split('.')[0])\n",
    "        Session = (Sessn1+1)*100 + Sessn2+1 # yes this makes the session numbers huge out of nowhere, but it won't overlap with QIOSKs proper numbering that goes up to 99\n",
    "    else:\n",
    "        Session = int(f[3][6:8])\n",
    "    fileSize = os.path.getsize(eq_file_loc)\n",
    "    \n",
    "    V = pd.read_csv(eq_file_loc,skipinitialspace=True)\n",
    "    if len(V)==0:\n",
    "        File_dets={'Signal':Signal, #f[-2].split('_')[-1],\n",
    "           'DevName':DevName,\n",
    "           'ID':DevID, \n",
    "           'Date':fileDate,\n",
    "           'Session':Session,\n",
    "           'FileName':file_name,\n",
    "           'FileType':'csv',\n",
    "           'FileSize': fileSize,\n",
    "           'RecStart':pd.to_datetime('2020-02-02 02:02:00.00+0000'), # fake start\n",
    "           'FullLoc':eq_file_loc}\n",
    "        return File_dets\n",
    "    \n",
    "    else:\n",
    "        V['DateTime'] = pd.to_datetime(V['DateTime'])\n",
    "        rec_start = V['DateTime'].iloc[0]\n",
    "        rec_end = V['DateTime'].iloc[-1]\n",
    "        rec_dur=(rec_end-rec_start).total_seconds()\n",
    "        Batt_start = V['BATTERY(mV)'].iloc[0]\n",
    "        Batt_end = V['BATTERY(mV)'].iloc[-1]\n",
    "        Batt_spend=(Batt_end-Batt_start)     \n",
    "        \n",
    "        a = V.loc[:,['SENSOR ID', 'SUBJECT ID', 'SUBJECT AGE', 'HR(BPM)',\n",
    "           'HRC(%)', 'BELT OFF', 'LEAD OFF', 'MOTION', 'BODY POSITION']].mode().loc[0]\n",
    "        DevNames = V.loc[:,'SUBJECT ID'].unique()\n",
    "\n",
    "        File_dets={'Signal':Signal, #f[-2].split('_')[-1],\n",
    "           'DevName':DevName,\n",
    "           'ID':DevID, \n",
    "           'Date':fileDate,\n",
    "           'Session':Session,\n",
    "           'FileName':file_name,\n",
    "           'FileType':'csv',\n",
    "           'FileSize': fileSize,\n",
    "           'RecStart':rec_start,\n",
    "           'RecEnd':rec_end,\n",
    "           'Duration':rec_dur,\n",
    "           'BatteryStart':Batt_start,\n",
    "           'BatteryEnd':Batt_end,\n",
    "           'BatteryChange(mV)':Batt_spend,\n",
    "           'FullLoc':eq_file_loc,\n",
    "           'SubjectNames': DevNames}\n",
    "        File_dets.update(a) # dic0.update(dic1)\n",
    "        return File_dets\n",
    "\n",
    "def test_plot_signals(V): # V is a qiosk file read into pandas\n",
    "    if len(V)>2:\n",
    "        V['DateTime'] = pd.to_datetime(V['DateTime'])\n",
    "        W = V.select_dtypes(include=['int64','float64'])\n",
    "        W.set_index(V['DateTime'],inplace=True)\n",
    "        cols = W.columns\n",
    "        # excerpt a minute of signal from the middle of the recording\n",
    "        if V['DateTime'].iloc[-1]-V['DateTime'].iloc[0]>pd.to_timedelta(120,'s'):\n",
    "            t1 =  V['DateTime'].iloc[int(len(V)/2)]\n",
    "            t2 = t1+pd.to_timedelta(60,'s')\n",
    "            X = W.loc[W.index>t1,:].copy()\n",
    "            X = X.loc[X.index<t2,:].copy()\n",
    "            for c in cols:\n",
    "                fig, (ax1, ax2) = plt.subplots(1,2,figsize=[15,2])\n",
    "                W[c].plot(ax=ax1)\n",
    "                ax1.set_ylabel(c)\n",
    "                X.loc[:,c].plot(ax=ax2)\n",
    "                ax2.set_xlabel('60 seconds')\n",
    "                plt.show()\n",
    "        else:\n",
    "            for c in cols:\n",
    "                fig, (ax1) = plt.subplots(1,1,figsize=[15,2])\n",
    "                W[c].plot(ax=ax1)\n",
    "                ax1.set_ylabel(c)\n",
    "                plt.show()\n",
    "    else:\n",
    "        print('Not enough data')\n",
    "        \n",
    "def test_plot_signals_interval(V,t1,t2): # V is a qiosk file read into pandas\n",
    "    # its on you to be sure these time stamps are within the recording interval of the file\n",
    "    if len(V)>2:\n",
    "        V['DateTime'] = pd.to_datetime(V['DateTime'])\n",
    "        W = V.select_dtypes(include=['int64','float64'])\n",
    "        W.set_index(V['DateTime'],inplace=True)\n",
    "        cols = W.columns\n",
    "        X = W.loc[W.index>t1,:].copy()\n",
    "        X = X.loc[X.index<t2,:].copy()\n",
    "        for c in cols:\n",
    "            fig, (ax1) = plt.subplots(1,1,figsize=[15,2])\n",
    "            X.loc[:,c].plot(ax=ax1)\n",
    "            ax1.set_ylabel(c)\n",
    "            plt.show()\n",
    "    else:\n",
    "        print('No data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "def matched_files(eq_file_loc,data_path):\n",
    "    # from the location of a good file and the location of other files, retrieve the location of all matching files\n",
    "    dfile = min_dets(eq_file_loc)\n",
    "    \n",
    "    # retrieve the files in that path that match \n",
    "    file_locs = []\n",
    "    for root, dirs, files in os.walk(data_path):\n",
    "        for file in files:\n",
    "            if(file.lower().endswith(\".csv\")):\n",
    "                file_locs.append(os.path.join(root,file))\n",
    "    k=[]\n",
    "    for file in file_locs:\n",
    "        if not file.lower().endswith('recordings.csv'):\n",
    "            File_dets=min_dets_sem(file)\n",
    "            k.append(File_dets)\n",
    "    df_files=pd.DataFrame(data=k)\n",
    "\n",
    "    match_fields = ['ID','DevName','Date','Session']\n",
    "\n",
    "    matched_files = df_files.loc[df_files['ID'] == dfile['ID']]\n",
    "    for mf in match_fields[1:]:\n",
    "        matched_files = matched_files.loc[matched_files[mf] == dfile[mf]]\n",
    "\n",
    "    return list(matched_files['FullLoc'])+list(matched_files['SEMLoc'].unique())\n",
    "    \n",
    "\n",
    "def min_dets_sem(eq_file_loc): # for files output by the lab manager desktop app, so far\n",
    "    w = eq_file_loc.split('\\\\')\n",
    "    file_name = w[-1]\n",
    "    f = file_name.split('-')\n",
    "    Signal = f[0]\n",
    "    DevName = f[1]#filings[-2]\n",
    "    DevID = int(f[2])\n",
    "    fileDate = int(f[3][:6]) # interpret as datetime datatype?\n",
    "    # sometimes the session numbering fails and we get files with the same session number but an additiona _0 or _1\n",
    "    # how to number this? What errors are producing these session numbers?\n",
    "    if len(f[3].split('_'))==2: # we have an additional numbering to work into the sessions. :[\n",
    "        Sessn1 = int(f[3].split('_')[0][6:8])\n",
    "        Sessn2 = int(f[3].split('_')[1].split('.')[0])\n",
    "        Session = (Sessn1+1)*100 + Sessn2+1 # yes this makes the session numbers huge out of nowhere, but it won't overlap with QIOSKs proper numbering that goes up to 99\n",
    "    else:\n",
    "        Session = int(f[3][6:8])\n",
    "    fileSize = os.path.getsize(eq_file_loc)\n",
    "    \n",
    "    # assuming qiosks file structure is consistent, SEM file naming should be reliable\n",
    "    if eq_file_loc.startswith('C:\\\\Users\\\\Public\\\\Documents\\\\Equivital\\\\Equivital Manager Wizard\\\\'): # initial qiosk exports\n",
    "        fn = w[-1].split('-')[-1][:-3]+'SEM'\n",
    "        sem_path = w[:-3]+['Raw SEM Data',w[-2],fn]\n",
    "        sem_loc = '\\\\'.join(sem_path)\n",
    "    else:\n",
    "        if w[-2].lower().startswith('csv'): # Use earlier details to formulate location and structure\n",
    "            fn = file_name.split('-')[-1][:-3]+'SEM'\n",
    "            sem_path = eq_file_loc.split('\\\\')[:-2] + ['SEM',DevName,fn]\n",
    "            sem_loc = '\\\\'.join(sem_path)\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "    File_dets={'Signal':Signal, #f[-2].split('_')[-1],\n",
    "       'DevName':DevName,\n",
    "       'ID':DevID, \n",
    "       'Date':fileDate,\n",
    "       'Session':Session,\n",
    "       'FileName':file_name,\n",
    "       'FileType':'csv',\n",
    "       'FileSize': fileSize,\n",
    "       'FullLoc':eq_file_loc,\n",
    "       'SEMLoc': sem_loc}\n",
    "    return File_dets\n",
    "\n",
    "def qiosk_recordings(projectpath,projecttag):\n",
    "    file_locs = []\n",
    "    for root, dirs, files in os.walk(projectpath):\n",
    "        for file in files:\n",
    "            if(file.lower().endswith(\".csv\")):\n",
    "                if file.lower().startswith('data'):\n",
    "                    file_locs.append(os.path.join(root,file))\n",
    "    if len(file_locs)>0:\n",
    "        k=[]           \n",
    "        for f in file_locs:\n",
    "            File_dets=data_dets(f)\n",
    "            if File_dets:\n",
    "                k.append(File_dets)\n",
    "        df_datafiles=pd.DataFrame(data=k)#\n",
    "        df_datafiles=df_datafiles.sort_values(by='RecStart').reset_index(drop=True)\n",
    "        df_datafiles.to_csv(projectpath + projecttag + '_Qiosk_recordings.csv')\n",
    "        return df_datafiles\n",
    "    else:\n",
    "        print('Path is empty of DATA files.')\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scan for DATA files\n",
    "\n",
    "All recordinds exported by Qiosk produce four CSV files and one SEM file. One of the CSVs is a DATA file that contains metadata and some essential signal quality checks on 15 s intervals.\n",
    "\n",
    "We can ID instances of signal recordings from statistics taken out of the DATA file, so that gets extracted first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path is empty of DATA files.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# location of the files when exported by QIOSK\n",
    "path = \"C:\\\\Users\\\\Public\\\\Documents\\\\Equivital\\\\Equivital Manager Wizard\\\\\"#Extracted SEM Data\\\\\" #\"../Equivital/Equivital Manager Wizard/Extracted SEM Data/\"\n",
    "#os.listdir(path)\n",
    "\n",
    "df_datafiles = qiosk_recordings(path,'Present')\n",
    "df_datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of DATA files: 211\n",
      "[3420415 5022164 5022060 5022138 5022126 5022139 5022141 5022050 5022281\n",
      " 5022299 3420427 3420456 5022166 5022285 5022027 5022241 5022110 5022247\n",
      " 5022198 5022193 5022222 5022058 3420755 3420426 5022077 5022156 5022297\n",
      " 5022143 5022202 5022173 5022098 5022176 5022076 5022010 5022155 5022100\n",
      " 5022161 5023926 5022154 5022238 5022244 5022149 5022127 5022031 5022062\n",
      " 5022204 5022104 5022179 5022057 5022203 5022151 5022245 5022234 5022026\n",
      " 5022184 5022051 5022009 5022006 5022117 5022073 5022152 5022256 5022101\n",
      " 5022142 5022207 5022131 5022163 5022002 5022240 5022292]\n",
      "['Bluetooth_Tester_1' 'Pilot_31' 'Pilot_32' 'Pilot_4' 'Pilot_5' 'Pilot_6'\n",
      " 'Pilot_30' 'Pilot_7' 'Pilot_8' 'Pilot_9' 'Pilot_3' 'Pilot_2' 'Pilot_20'\n",
      " 'Pilot_21' 'Pilot_22' 'Pilot_23' 'Pilot_24' 'Pilot_25' 'Pilot_26'\n",
      " 'Pilot_27' 'Pilot_28' 'Pilot_29' 'Test1' 'Test3_On' 'Test4' 'Test5'\n",
      " 'Test2' 'Test2_On' 'Pilot 39' 'Pilot 40' 'Pilot 41' 'Pilot 42' 'Pilot 43'\n",
      " 'Pilot 38' 'Pilot 37' 'Bluetooth_Tester_2' 'Bluetooth_Tester_3'\n",
      " 'Pilot 33' 'Pilot 34' 'Pilot 35' 'Pilot 36' 'Pilot 44' 'Pilot 45'\n",
      " 'Pilot 64' 'Pilot 65' 'Pilot 66' 'Pilot 67' 'Pilot_1' 'Pilot_10'\n",
      " 'Pilot_11' 'Pilot_12' 'Pilot 63' 'Pilot_13' 'Pilot_15' 'Pilot_16'\n",
      " 'Pilot_17' 'Pilot_18' 'Pilot_19' 'Pilot_14' 'Pilot 62' 'Pilot 61'\n",
      " 'Pilot 60' 'Pilot 46' 'Pilot 47' 'Pilot 48' 'Pilot 49' 'Pilot 50'\n",
      " 'Pilot 51' 'Pilot 52' 'Pilot 53' 'Pilot 54' 'Pilot 55' 'Pilot 56'\n",
      " 'Pilot 57' 'Pilot 58' 'Pilot 59']\n",
      "[230126 230120 230123 230127 230130 221206 230117 230125 230118 230119\n",
      " 230128 230131    101 230116]\n"
     ]
    }
   ],
   "source": [
    "print('Number of DATA files: '+ str(len(df_datafiles)))\n",
    "# key categories to structure of Qiosk output DATA files\n",
    "print(df_datafiles['ID'].unique())\n",
    "print(df_datafiles['DevName'].unique())\n",
    "print(df_datafiles['Date'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define set of recordings to move\n",
    "First specify a subset by either device number (singular) or day of recording event.\n",
    "\n",
    "Next this subset can be refined by restricting recordings to a specific time of day: to have started before a particular time (when you know the recording was happening) and/or to have ended after a specific time (when you know the recording was happening.\n",
    "\n",
    "All times are in UTC, which is an hour earlier than Central European Time, 2 hours earlier than Central European Summer Time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA files from one device, by device ID numbr\n",
    "devN = 5022299\n",
    "s_files=df_datafiles.loc[df_datafiles['ID'] == devN,:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA files from recordings on a particular day, YYMMDD\n",
    "recDate = 230201\n",
    "s_files=df_datafiles.loc[df_datafiles['Date'] == recDate,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA files from recordings that lasted longer than N seconds\n",
    "minDuration = 600  \n",
    "s_files=df_datafiles.loc[df_datafiles['Duration'] > minDuration,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA files from recordings that are smaller than N Bytes\n",
    "maxfileSize = 200  \n",
    "s_files=df_datafiles.loc[df_datafiles['FileSize'] < maxfileSize,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recordings started before a certain time \n",
    "t = pd.to_datetime('2023-02-01 12:02:00.00+0000')# V['DateTime'].iloc[int(len(V)/2)]   2023-01-18 13:30:09 2023-01-18 13:43:27\n",
    "s_files=s_files.loc[s_files['RecStart']< t,:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recordings ended after a certain time\n",
    "t = pd.to_datetime('2023-01-28 00:00:00.00+0000')# V['DateTime'].iloc[int(len(V)/2)]   2023-01-18 13:30:09 2023-01-18 13:43:27\n",
    "s_files=s_files.loc[s_files['RecEnd']> t,:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Signal</th>\n",
       "      <th>DevName</th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Session</th>\n",
       "      <th>FileName</th>\n",
       "      <th>FileType</th>\n",
       "      <th>FileSize</th>\n",
       "      <th>RecStart</th>\n",
       "      <th>FullLoc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DATA</td>\n",
       "      <td>Bluetooth_Tester_1</td>\n",
       "      <td>3420415</td>\n",
       "      <td>230126</td>\n",
       "      <td>0</td>\n",
       "      <td>DATA-Bluetooth_Tester_1-3420415-23012600.CSV</td>\n",
       "      <td>csv</td>\n",
       "      <td>109</td>\n",
       "      <td>2020-02-02 02:02:00+00:00</td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Equivital\\Equivital ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DATA</td>\n",
       "      <td>Pilot_31</td>\n",
       "      <td>5022164</td>\n",
       "      <td>230120</td>\n",
       "      <td>0</td>\n",
       "      <td>DATA-Pilot_31-5022164-23012000.CSV</td>\n",
       "      <td>csv</td>\n",
       "      <td>109</td>\n",
       "      <td>2020-02-02 02:02:00+00:00</td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Equivital\\Equivital ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DATA</td>\n",
       "      <td>Pilot_32</td>\n",
       "      <td>5022060</td>\n",
       "      <td>230123</td>\n",
       "      <td>0</td>\n",
       "      <td>DATA-Pilot_32-5022060-23012300.CSV</td>\n",
       "      <td>csv</td>\n",
       "      <td>109</td>\n",
       "      <td>2020-02-02 02:02:00+00:00</td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Equivital\\Equivital ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATA</td>\n",
       "      <td>Pilot_32</td>\n",
       "      <td>5022060</td>\n",
       "      <td>230126</td>\n",
       "      <td>0</td>\n",
       "      <td>DATA-Pilot_32-5022060-23012600.CSV</td>\n",
       "      <td>csv</td>\n",
       "      <td>109</td>\n",
       "      <td>2020-02-02 02:02:00+00:00</td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Equivital\\Equivital ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DATA</td>\n",
       "      <td>Pilot_32</td>\n",
       "      <td>5022060</td>\n",
       "      <td>230127</td>\n",
       "      <td>2</td>\n",
       "      <td>DATA-Pilot_32-5022060-23012702.CSV</td>\n",
       "      <td>csv</td>\n",
       "      <td>109</td>\n",
       "      <td>2020-02-02 02:02:00+00:00</td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Equivital\\Equivital ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>DATA</td>\n",
       "      <td>Pilot 57</td>\n",
       "      <td>5022002</td>\n",
       "      <td>230123</td>\n",
       "      <td>0</td>\n",
       "      <td>DATA-Pilot 57-5022002-23012300.CSV</td>\n",
       "      <td>csv</td>\n",
       "      <td>109</td>\n",
       "      <td>2020-02-02 02:02:00+00:00</td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Equivital\\Equivital ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>DATA</td>\n",
       "      <td>Pilot 58</td>\n",
       "      <td>5022240</td>\n",
       "      <td>230120</td>\n",
       "      <td>0</td>\n",
       "      <td>DATA-Pilot 58-5022240-23012000.CSV</td>\n",
       "      <td>csv</td>\n",
       "      <td>109</td>\n",
       "      <td>2020-02-02 02:02:00+00:00</td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Equivital\\Equivital ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>DATA</td>\n",
       "      <td>Pilot 59</td>\n",
       "      <td>5022292</td>\n",
       "      <td>230123</td>\n",
       "      <td>0</td>\n",
       "      <td>DATA-Pilot 59-5022292-23012300.CSV</td>\n",
       "      <td>csv</td>\n",
       "      <td>109</td>\n",
       "      <td>2020-02-02 02:02:00+00:00</td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Equivital\\Equivital ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>DATA</td>\n",
       "      <td>Pilot 44</td>\n",
       "      <td>5022161</td>\n",
       "      <td>230130</td>\n",
       "      <td>1</td>\n",
       "      <td>DATA-Pilot 44-5022161-23013001.CSV</td>\n",
       "      <td>csv</td>\n",
       "      <td>109</td>\n",
       "      <td>2020-02-02 02:02:00+00:00</td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Equivital\\Equivital ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>DATA</td>\n",
       "      <td>Test5</td>\n",
       "      <td>3420427</td>\n",
       "      <td>230126</td>\n",
       "      <td>0</td>\n",
       "      <td>DATA-Test5-3420427-23012600.CSV</td>\n",
       "      <td>csv</td>\n",
       "      <td>109</td>\n",
       "      <td>2020-02-02 02:02:00+00:00</td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Equivital\\Equivital ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Signal             DevName       ID    Date  Session  \\\n",
       "0     DATA  Bluetooth_Tester_1  3420415  230126        0   \n",
       "1     DATA            Pilot_31  5022164  230120        0   \n",
       "2     DATA            Pilot_32  5022060  230123        0   \n",
       "3     DATA            Pilot_32  5022060  230126        0   \n",
       "4     DATA            Pilot_32  5022060  230127        2   \n",
       "..     ...                 ...      ...     ...      ...   \n",
       "206   DATA            Pilot 57  5022002  230123        0   \n",
       "207   DATA            Pilot 58  5022240  230120        0   \n",
       "208   DATA            Pilot 59  5022292  230123        0   \n",
       "209   DATA            Pilot 44  5022161  230130        1   \n",
       "210   DATA               Test5  3420427  230126        0   \n",
       "\n",
       "                                         FileName FileType  FileSize  \\\n",
       "0    DATA-Bluetooth_Tester_1-3420415-23012600.CSV      csv       109   \n",
       "1              DATA-Pilot_31-5022164-23012000.CSV      csv       109   \n",
       "2              DATA-Pilot_32-5022060-23012300.CSV      csv       109   \n",
       "3              DATA-Pilot_32-5022060-23012600.CSV      csv       109   \n",
       "4              DATA-Pilot_32-5022060-23012702.CSV      csv       109   \n",
       "..                                            ...      ...       ...   \n",
       "206            DATA-Pilot 57-5022002-23012300.CSV      csv       109   \n",
       "207            DATA-Pilot 58-5022240-23012000.CSV      csv       109   \n",
       "208            DATA-Pilot 59-5022292-23012300.CSV      csv       109   \n",
       "209            DATA-Pilot 44-5022161-23013001.CSV      csv       109   \n",
       "210               DATA-Test5-3420427-23012600.CSV      csv       109   \n",
       "\n",
       "                     RecStart  \\\n",
       "0   2020-02-02 02:02:00+00:00   \n",
       "1   2020-02-02 02:02:00+00:00   \n",
       "2   2020-02-02 02:02:00+00:00   \n",
       "3   2020-02-02 02:02:00+00:00   \n",
       "4   2020-02-02 02:02:00+00:00   \n",
       "..                        ...   \n",
       "206 2020-02-02 02:02:00+00:00   \n",
       "207 2020-02-02 02:02:00+00:00   \n",
       "208 2020-02-02 02:02:00+00:00   \n",
       "209 2020-02-02 02:02:00+00:00   \n",
       "210 2020-02-02 02:02:00+00:00   \n",
       "\n",
       "                                               FullLoc  \n",
       "0    C:\\Users\\Public\\Documents\\Equivital\\Equivital ...  \n",
       "1    C:\\Users\\Public\\Documents\\Equivital\\Equivital ...  \n",
       "2    C:\\Users\\Public\\Documents\\Equivital\\Equivital ...  \n",
       "3    C:\\Users\\Public\\Documents\\Equivital\\Equivital ...  \n",
       "4    C:\\Users\\Public\\Documents\\Equivital\\Equivital ...  \n",
       "..                                                 ...  \n",
       "206  C:\\Users\\Public\\Documents\\Equivital\\Equivital ...  \n",
       "207  C:\\Users\\Public\\Documents\\Equivital\\Equivital ...  \n",
       "208  C:\\Users\\Public\\Documents\\Equivital\\Equivital ...  \n",
       "209  C:\\Users\\Public\\Documents\\Equivital\\Equivital ...  \n",
       "210  C:\\Users\\Public\\Documents\\Equivital\\Equivital ...  \n",
       "\n",
       "[211 rows x 10 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show subset of files\n",
    "s_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These recordings can be checked in View_Equivital_Qiosk_Export.\n",
    "\n",
    "Now we move them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move selected files to suitable project folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\Equivital\\Equivital Manager Wizard\\\n"
     ]
    }
   ],
   "source": [
    "projectsFolder = 'C:\\\\Users\\\\fourMs lab\\\\Documents\\\\Equivital\\\\ProjectData\\\\' # where qiosk files are moved to after export\n",
    "print(path) # where the qiosk files are initially saved by the Equivital Qiosk program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set project folder name\n",
    "#projectName = 'AlexanderStandStill'\n",
    "projectName = 'BatteryTests'\n",
    "#projectName = 'SoloRecordings'\n",
    "#projectName = 'Concert230128'\n",
    "#projectName = 'LauraTestRecording'\n",
    "projectPath = projectsFolder + projectName + '\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create folders for project to move files to\n",
    "Check target location for data files to keep and to remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the folder exists for project and set up locations\n",
    "if not os.path.isdir(projectsFolder + projectName):\n",
    "    os.mkdir(projectsFolder + projectName)\n",
    "    \n",
    "if not os.path.isdir(projectsFolder + projectName + '\\\\' + 'SEM'):\n",
    "    os.mkdir(projectsFolder + projectName + '\\\\' + 'SEM')\n",
    "if not os.path.isdir(projectsFolder + projectName + '\\\\' + 'CSV'):\n",
    "    os.mkdir(projectsFolder + projectName + '\\\\' + 'CSV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move CSV and SEM files to project folder\n",
    "Move them to project folder and generate their own present recordings file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Signal</th>\n",
       "      <th>DevName</th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Session</th>\n",
       "      <th>FileName</th>\n",
       "      <th>FileType</th>\n",
       "      <th>FileSize</th>\n",
       "      <th>RecStart</th>\n",
       "      <th>RecEnd</th>\n",
       "      <th>...</th>\n",
       "      <th>SubjectNames</th>\n",
       "      <th>SENSOR ID</th>\n",
       "      <th>SUBJECT ID</th>\n",
       "      <th>SUBJECT AGE</th>\n",
       "      <th>HR(BPM)</th>\n",
       "      <th>HRC(%)</th>\n",
       "      <th>BELT OFF</th>\n",
       "      <th>LEAD OFF</th>\n",
       "      <th>MOTION</th>\n",
       "      <th>BODY POSITION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DATA</td>\n",
       "      <td>Test3_On</td>\n",
       "      <td>3420755</td>\n",
       "      <td>230120</td>\n",
       "      <td>6</td>\n",
       "      <td>DATA-Test3_On-3420755-23012006.CSV</td>\n",
       "      <td>csv</td>\n",
       "      <td>864823</td>\n",
       "      <td>2023-01-20 15:06:18+00:00</td>\n",
       "      <td>2023-01-21 07:17:23+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>[Test3_On, Test5, Test4]</td>\n",
       "      <td>3420755.0</td>\n",
       "      <td>Test5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Stationary</td>\n",
       "      <td>Side</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DATA</td>\n",
       "      <td>Test5</td>\n",
       "      <td>3420427</td>\n",
       "      <td>230120</td>\n",
       "      <td>4</td>\n",
       "      <td>DATA-Test5-3420427-23012004.CSV</td>\n",
       "      <td>csv</td>\n",
       "      <td>854433</td>\n",
       "      <td>2023-01-20 15:06:20+00:00</td>\n",
       "      <td>2023-01-21 07:07:25+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>[Test5, Test3_On, Test4]</td>\n",
       "      <td>3420427.0</td>\n",
       "      <td>Test5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Stationary</td>\n",
       "      <td>Side</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DATA</td>\n",
       "      <td>Test2</td>\n",
       "      <td>3420426</td>\n",
       "      <td>230120</td>\n",
       "      <td>3</td>\n",
       "      <td>DATA-Test2-3420426-23012003.CSV</td>\n",
       "      <td>csv</td>\n",
       "      <td>1841283</td>\n",
       "      <td>2023-01-20 15:06:22+00:00</td>\n",
       "      <td>2023-01-22 01:39:42+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>[Test2, Test1]</td>\n",
       "      <td>3420426.0</td>\n",
       "      <td>Test2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Stationary</td>\n",
       "      <td>Side</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATA</td>\n",
       "      <td>Test4</td>\n",
       "      <td>3420456</td>\n",
       "      <td>230120</td>\n",
       "      <td>4</td>\n",
       "      <td>DATA-Test4-3420456-23012004.CSV</td>\n",
       "      <td>csv</td>\n",
       "      <td>820775</td>\n",
       "      <td>2023-01-20 15:06:25+00:00</td>\n",
       "      <td>2023-01-21 06:30:30+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>[Test4, Test5, Test3_On]</td>\n",
       "      <td>3420456.0</td>\n",
       "      <td>Test5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Stationary</td>\n",
       "      <td>Side</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DATA</td>\n",
       "      <td>Pilot_11</td>\n",
       "      <td>5022031</td>\n",
       "      <td>230127</td>\n",
       "      <td>0</td>\n",
       "      <td>DATA-Pilot_11-5022031-23012700.CSV</td>\n",
       "      <td>csv</td>\n",
       "      <td>805075</td>\n",
       "      <td>2023-01-27 11:10:58+00:00</td>\n",
       "      <td>2023-01-29 06:39:13+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>[Pilot_11, Pilot_22]</td>\n",
       "      <td>5022031.0</td>\n",
       "      <td>Pilot_11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Stationary</td>\n",
       "      <td>Side</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>DATA</td>\n",
       "      <td>Pilot_31</td>\n",
       "      <td>5022164</td>\n",
       "      <td>230127</td>\n",
       "      <td>101</td>\n",
       "      <td>DATA-Pilot_31-5022164-23012700_0.CSV</td>\n",
       "      <td>csv</td>\n",
       "      <td>815853</td>\n",
       "      <td>2023-01-27 15:40:15+00:00</td>\n",
       "      <td>2023-01-29 11:09:00+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>[Pilot_31, Pilot_29, Pilot_12, Pilot_23]</td>\n",
       "      <td>5022164.0</td>\n",
       "      <td>Pilot_23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Stationary</td>\n",
       "      <td>Prone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>DATA</td>\n",
       "      <td>Pilot_32</td>\n",
       "      <td>5022060</td>\n",
       "      <td>230127</td>\n",
       "      <td>101</td>\n",
       "      <td>DATA-Pilot_32-5022060-23012700_0.CSV</td>\n",
       "      <td>csv</td>\n",
       "      <td>831779</td>\n",
       "      <td>2023-01-27 15:40:15+00:00</td>\n",
       "      <td>2023-01-29 12:31:45+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>[Pilot_32, Pilot_1, Pilot_9, Pilot_3, Pilot_4,...</td>\n",
       "      <td>5022060.0</td>\n",
       "      <td>Pilot_9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Stationary</td>\n",
       "      <td>Prone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>DATA</td>\n",
       "      <td>Pilot_23</td>\n",
       "      <td>5022241</td>\n",
       "      <td>230127</td>\n",
       "      <td>101</td>\n",
       "      <td>DATA-Pilot_23-5022241-23012700_0.CSV</td>\n",
       "      <td>csv</td>\n",
       "      <td>815397</td>\n",
       "      <td>2023-01-27 15:40:15+00:00</td>\n",
       "      <td>2023-01-29 11:09:45+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>[Pilot_23, Pilot_25, Pilot_14, Pilot_20]</td>\n",
       "      <td>5022241.0</td>\n",
       "      <td>Pilot_23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Stationary</td>\n",
       "      <td>Prone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>DATA</td>\n",
       "      <td>Pilot_24</td>\n",
       "      <td>5022110</td>\n",
       "      <td>230127</td>\n",
       "      <td>0</td>\n",
       "      <td>DATA-Pilot_24-5022110-23012700.CSV</td>\n",
       "      <td>csv</td>\n",
       "      <td>831767</td>\n",
       "      <td>2023-01-27 15:40:15+00:00</td>\n",
       "      <td>2023-01-29 12:28:45+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>[Pilot_24, Pilot_32, Pilot_1, Pilot_9, Pilot_3]</td>\n",
       "      <td>5022110.0</td>\n",
       "      <td>Pilot_24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Stationary</td>\n",
       "      <td>Prone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>DATA</td>\n",
       "      <td>Pilot_28</td>\n",
       "      <td>5022222</td>\n",
       "      <td>230127</td>\n",
       "      <td>101</td>\n",
       "      <td>DATA-Pilot_28-5022222-23012700_0.CSV</td>\n",
       "      <td>csv</td>\n",
       "      <td>825143</td>\n",
       "      <td>2023-01-27 15:40:16+00:00</td>\n",
       "      <td>2023-01-29 11:37:16+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>[Pilot_10, Pilot_18]</td>\n",
       "      <td>5022222.0</td>\n",
       "      <td>Pilot_18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Stationary</td>\n",
       "      <td>Prone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Signal   DevName       ID    Date  Session  \\\n",
       "0    DATA  Test3_On  3420755  230120        6   \n",
       "1    DATA     Test5  3420427  230120        4   \n",
       "2    DATA     Test2  3420426  230120        3   \n",
       "3    DATA     Test4  3420456  230120        4   \n",
       "4    DATA  Pilot_11  5022031  230127        0   \n",
       "..    ...       ...      ...     ...      ...   \n",
       "63   DATA  Pilot_31  5022164  230127      101   \n",
       "64   DATA  Pilot_32  5022060  230127      101   \n",
       "65   DATA  Pilot_23  5022241  230127      101   \n",
       "66   DATA  Pilot_24  5022110  230127        0   \n",
       "67   DATA  Pilot_28  5022222  230127      101   \n",
       "\n",
       "                                FileName FileType  FileSize  \\\n",
       "0     DATA-Test3_On-3420755-23012006.CSV      csv    864823   \n",
       "1        DATA-Test5-3420427-23012004.CSV      csv    854433   \n",
       "2        DATA-Test2-3420426-23012003.CSV      csv   1841283   \n",
       "3        DATA-Test4-3420456-23012004.CSV      csv    820775   \n",
       "4     DATA-Pilot_11-5022031-23012700.CSV      csv    805075   \n",
       "..                                   ...      ...       ...   \n",
       "63  DATA-Pilot_31-5022164-23012700_0.CSV      csv    815853   \n",
       "64  DATA-Pilot_32-5022060-23012700_0.CSV      csv    831779   \n",
       "65  DATA-Pilot_23-5022241-23012700_0.CSV      csv    815397   \n",
       "66    DATA-Pilot_24-5022110-23012700.CSV      csv    831767   \n",
       "67  DATA-Pilot_28-5022222-23012700_0.CSV      csv    825143   \n",
       "\n",
       "                    RecStart                    RecEnd  ...  \\\n",
       "0  2023-01-20 15:06:18+00:00 2023-01-21 07:17:23+00:00  ...   \n",
       "1  2023-01-20 15:06:20+00:00 2023-01-21 07:07:25+00:00  ...   \n",
       "2  2023-01-20 15:06:22+00:00 2023-01-22 01:39:42+00:00  ...   \n",
       "3  2023-01-20 15:06:25+00:00 2023-01-21 06:30:30+00:00  ...   \n",
       "4  2023-01-27 11:10:58+00:00 2023-01-29 06:39:13+00:00  ...   \n",
       "..                       ...                       ...  ...   \n",
       "63 2023-01-27 15:40:15+00:00 2023-01-29 11:09:00+00:00  ...   \n",
       "64 2023-01-27 15:40:15+00:00 2023-01-29 12:31:45+00:00  ...   \n",
       "65 2023-01-27 15:40:15+00:00 2023-01-29 11:09:45+00:00  ...   \n",
       "66 2023-01-27 15:40:15+00:00 2023-01-29 12:28:45+00:00  ...   \n",
       "67 2023-01-27 15:40:16+00:00 2023-01-29 11:37:16+00:00  ...   \n",
       "\n",
       "                                         SubjectNames  SENSOR ID  SUBJECT ID  \\\n",
       "0                            [Test3_On, Test5, Test4]  3420755.0       Test5   \n",
       "1                            [Test5, Test3_On, Test4]  3420427.0       Test5   \n",
       "2                                      [Test2, Test1]  3420426.0       Test2   \n",
       "3                            [Test4, Test5, Test3_On]  3420456.0       Test5   \n",
       "4                                [Pilot_11, Pilot_22]  5022031.0    Pilot_11   \n",
       "..                                                ...        ...         ...   \n",
       "63           [Pilot_31, Pilot_29, Pilot_12, Pilot_23]  5022164.0    Pilot_23   \n",
       "64  [Pilot_32, Pilot_1, Pilot_9, Pilot_3, Pilot_4,...  5022060.0     Pilot_9   \n",
       "65           [Pilot_23, Pilot_25, Pilot_14, Pilot_20]  5022241.0    Pilot_23   \n",
       "66    [Pilot_24, Pilot_32, Pilot_1, Pilot_9, Pilot_3]  5022110.0    Pilot_24   \n",
       "67                               [Pilot_10, Pilot_18]  5022222.0    Pilot_18   \n",
       "\n",
       "    SUBJECT AGE HR(BPM) HRC(%)  BELT OFF LEAD OFF      MOTION  BODY POSITION  \n",
       "0           NaN       0    100         1        1  Stationary           Side  \n",
       "1           NaN       0    100         1        1  Stationary           Side  \n",
       "2           NaN       0    100         1        1  Stationary           Side  \n",
       "3           NaN       0    100         1        1  Stationary           Side  \n",
       "4           NaN       0    100         1        1  Stationary           Side  \n",
       "..          ...     ...    ...       ...      ...         ...            ...  \n",
       "63          NaN      16    100         1        1  Stationary          Prone  \n",
       "64          NaN      16    100         1        1  Stationary          Prone  \n",
       "65          NaN      38     98         1        1  Stationary          Prone  \n",
       "66          NaN       6    100         1        1  Stationary          Prone  \n",
       "67          NaN      22    100         1        1  Stationary          Prone  \n",
       "\n",
       "[68 rows x 25 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i,row in s_files.iterrows():\n",
    "    dataFile = row['FullLoc']\n",
    "    matched = matched_files(dataFile,path) # outputs locations of csv and sem files\n",
    "    \n",
    "    for fi in matched:\n",
    "        fileName = fi.split('\\\\')[-1]\n",
    "        devName = row['DevName']\n",
    "        if fileName.lower().endswith('csv'):\n",
    "            if not fileName.lower().endswith('Recordings.csv'):\n",
    "                out_f = projectPath + 'CSV\\\\' + fileName\n",
    "                os.rename(fi,out_f)\n",
    "        if fileName.lower().endswith('sem'):\n",
    "            if not os.path.isdir(projectsFolder + projectName + '\\\\SEM\\\\' + devName):\n",
    "                os.mkdir(projectsFolder + projectName  + '\\\\SEM\\\\' + devName)\n",
    "            out_f = projectPath + 'SEM\\\\' + devName  + '\\\\' + fileName\n",
    "            os.rename(fi,out_f)\n",
    "            \n",
    "dfiles = qiosk_recordings(projectPath,projectName)\n",
    "dfiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clear Recordings to ToBeDeleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366\n"
     ]
    }
   ],
   "source": [
    "# if these are files to be discarded store the DATA file indexes to discardRecs\n",
    "discardRecs = s_files.index\n",
    "projTag = 'ToBeDiscarded'\n",
    "discardPath = 'C:\\\\Users\\\\fourMs lab\\\\Documents\\\\Equivital\\\\ProjectData\\\\ToBeDeleted\\\\'\n",
    "\n",
    "for i,row in s_files.iterrows():\n",
    "    dataFile = row['FullLoc']\n",
    "    matched = matched_files(dataFile,path) # outputs locations of csv and sem files\n",
    "    \n",
    "    for f in matched:\n",
    "        fileName = f.split('\\\\')[-1]\n",
    "        devName = row['DevName']\n",
    "        if f.lower().endswith('csv'):\n",
    "            out_f = discardPath + 'CSV\\\\' + fileName\n",
    "            os.rename(f,out_f)\n",
    "        if f.lower().endswith('sem'):\n",
    "            if not os.path.isdir(discardPath + 'SEM\\\\' + devName):\n",
    "                os.mkdir(discardPath + 'SEM\\\\' + devName)\n",
    "            out_f = discardPath + 'SEM\\\\' + devName + '\\\\' + fileName\n",
    "            os.rename(f,out_f)\n",
    "            \n",
    "dfiles = qiosk_recordings(discardPath,projTag)\n",
    "print(len(dfiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# if Files need to be moved between project folders\n",
    "\n",
    "Set the origin project name and target project name, collect the existing files at that location, chose the subset of recordings to move or copy, move or copy them, generate recording list in each location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Signal</th>\n",
       "      <th>DevName</th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Session</th>\n",
       "      <th>FileName</th>\n",
       "      <th>FileType</th>\n",
       "      <th>FileSize</th>\n",
       "      <th>RecStart</th>\n",
       "      <th>RecEnd</th>\n",
       "      <th>...</th>\n",
       "      <th>SubjectNames</th>\n",
       "      <th>SENSOR ID</th>\n",
       "      <th>SUBJECT ID</th>\n",
       "      <th>SUBJECT AGE</th>\n",
       "      <th>HR(BPM)</th>\n",
       "      <th>HRC(%)</th>\n",
       "      <th>BELT OFF</th>\n",
       "      <th>LEAD OFF</th>\n",
       "      <th>MOTION</th>\n",
       "      <th>BODY POSITION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DATA</td>\n",
       "      <td>Pilot_11</td>\n",
       "      <td>5022031</td>\n",
       "      <td>230127</td>\n",
       "      <td>0</td>\n",
       "      <td>DATA-Pilot_11-5022031-23012700.CSV</td>\n",
       "      <td>csv</td>\n",
       "      <td>805075</td>\n",
       "      <td>2023-01-27 11:10:58+00:00</td>\n",
       "      <td>2023-01-29 06:39:13+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>[Pilot_11, Pilot_22]</td>\n",
       "      <td>5022031</td>\n",
       "      <td>Pilot_11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Stationary</td>\n",
       "      <td>Side</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Signal   DevName       ID    Date  Session  \\\n",
       "0   DATA  Pilot_11  5022031  230127        0   \n",
       "\n",
       "                             FileName FileType  FileSize  \\\n",
       "0  DATA-Pilot_11-5022031-23012700.CSV      csv    805075   \n",
       "\n",
       "                   RecStart                    RecEnd  ...  \\\n",
       "0 2023-01-27 11:10:58+00:00 2023-01-29 06:39:13+00:00  ...   \n",
       "\n",
       "           SubjectNames  SENSOR ID  SUBJECT ID  SUBJECT AGE HR(BPM) HRC(%)  \\\n",
       "0  [Pilot_11, Pilot_22]    5022031    Pilot_11          NaN       0    100   \n",
       "\n",
       "   BELT OFF LEAD OFF      MOTION  BODY POSITION  \n",
       "0         1        1  Stationary           Side  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# incase files need to be shifted from a project folder\n",
    "projectName = 'BatteryTests'\n",
    "projectPath = projectsFolder + projectName + '\\\\'\n",
    "projectPath1 = projectPath\n",
    "projectName1 = projectName\n",
    "\n",
    "s_files = qiosk_recordings(projectPath1,projectName1)\n",
    "s_files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get subset of s_files as you see fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project these files should be moved to\n",
    "projectName = 'Concert230128'\n",
    "# check if the folder exists for project and set up locations\n",
    "if not os.path.isdir(projectsFolder + projectName):\n",
    "    os.mkdir(projectsFolder + projectName)\n",
    "    \n",
    "if not os.path.isdir(projectsFolder + projectName + '\\\\' + 'SEM'):\n",
    "    os.mkdir(projectsFolder + projectName + '\\\\' + 'SEM')\n",
    "if not os.path.isdir(projectsFolder + projectName + '\\\\' + 'CSV'):\n",
    "    os.mkdir(projectsFolder + projectName + '\\\\' + 'CSV')\n",
    "    \n",
    "projectPath = projectsFolder + projectName + '\\\\'\n",
    "projectPath2 = projectPath\n",
    "projectName2 = projectName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\fourMs lab\\\\Documents\\\\Equivital\\\\ProjectData\\\\LauraTestRecording\\\\LauraTestRecording_QIOSK_Recordings.csv', 'C:\\\\Users\\\\fourMs lab\\\\Documents\\\\Equivital\\\\ProjectData\\\\LauraTestRecording\\\\CSV\\\\DATA-Pilot_11-5022031-23012700.CSV']\n",
      "C:\\Users\\fourMs lab\\Documents\\Equivital\\ProjectData\\LauraTestRecording\\CSV\\DATA-Pilot_11-5022031-23012700.CSV\n",
      "C:\\Users\\fourMs lab\\Documents\\Equivital\\ProjectData\\LauraTestRecording\\SEM\\Pilot_11\\23012700.SEM\n"
     ]
    }
   ],
   "source": [
    "# move s_files\n",
    "for i,row in s_files.iterrows():\n",
    "    dataFile = row['FullLoc']\n",
    "    matched = matched_files(dataFile,path) # outputs locations of csv and sem files\n",
    "    \n",
    "    for fi in matched:\n",
    "        fileName = fi.split('\\\\')[-1]\n",
    "        devName = row['DevName']\n",
    "        if fileName.lower().endswith('csv'):\n",
    "            if not fileName.lower().endswith('Recordings.csv'):\n",
    "                out_f = projectPath + 'CSV\\\\' + fileName\n",
    "                os.rename(fi,out_f)\n",
    "        if fileName.lower().endswith('sem'):\n",
    "            if not os.path.isdir(projectsFolder + projectName + '\\\\SEM\\\\' + devName):\n",
    "                os.mkdir(projectsFolder + projectName  + '\\\\SEM\\\\' + devName)\n",
    "            out_f = projectPath + 'SEM\\\\' + devName  + '\\\\' + fileName\n",
    "            os.rename(fi,out_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\fourMs lab\\\\Documents\\\\Equivital\\\\ProjectData\\\\LauraTestRecording\\\\LauraTestRecording_QIOSK_Recordings.csv', 'C:\\\\Users\\\\fourMs lab\\\\Documents\\\\Equivital\\\\ProjectData\\\\LauraTestRecording\\\\CSV\\\\DATA-Pilot_11-5022031-23012700.CSV']\n",
      "C:\\Users\\fourMs lab\\Documents\\Equivital\\ProjectData\\LauraTestRecording\\CSV\\DATA-Pilot_11-5022031-23012700.CSV\n",
      "C:\\Users\\fourMs lab\\Documents\\Equivital\\ProjectData\\LauraTestRecording\\SEM\\Pilot_11\\23012700.SEM\n"
     ]
    }
   ],
   "source": [
    "# COPY s_files\n",
    "for i,row in s_files.iterrows():\n",
    "    dataFile = row['FullLoc']\n",
    "    matched = matched_files(dataFile,path) # outputs locations of csv and sem files\n",
    "    \n",
    "    for fi in matched:\n",
    "        fileName = fi.split('\\\\')[-1]\n",
    "        devName = row['DevName']\n",
    "        if fileName.lower().endswith('csv'):\n",
    "            if not fileName.lower().endswith('Recordings.csv'):\n",
    "                out_f = projectPath + 'CSV\\\\' + fileName\n",
    "                os.system('cp ' + fi + ' ' + out_f)\n",
    "        if fileName.lower().endswith('sem'):\n",
    "            if not os.path.isdir(projectsFolder + projectName + '\\\\SEM\\\\' + devName):\n",
    "                os.mkdir(projectsFolder + projectName  + '\\\\SEM\\\\' + devName)\n",
    "            out_f = projectPath + 'SEM\\\\' + devName  + '\\\\' + fileName\n",
    "            os.system('cp ' + fi + ' ' + out_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qiosk_recordings(projectPath1,projectName1)\n",
    "dfiles = qiosk_recordings(projectPath2,projectName2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
